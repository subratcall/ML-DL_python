{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    reviewsFile = open('../data/reviews.txt','r')\n",
    "    reviews = list(map(lambda x:x[:-1],reviewsFile.readlines()))\n",
    "    reviewsFile.close()\n",
    "\n",
    "    labelsFile = open('../data/labels.txt','r')\n",
    "    labels = list(map(lambda x:x[:-1],labelsFile.readlines()))\n",
    "    labelsFile.close()\n",
    "    \n",
    "    return reviews,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews,labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(\"\\w+\\'?\\w+|\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptionStopWords = {\n",
    "    'again',\n",
    "    'against',\n",
    "    'ain',\n",
    "    'almost',\n",
    "    'among',\n",
    "    'amongst',\n",
    "    'amount',\n",
    "    'anyhow',\n",
    "    'anyway',\n",
    "    'aren',\n",
    "    \"aren't\",\n",
    "    'below',\n",
    "    'bottom',\n",
    "    'but',\n",
    "    'cannot',\n",
    "    'couldn',\n",
    "    \"couldn't\",\n",
    "    'didn',\n",
    "    \"didn't\",\n",
    "    'doesn',\n",
    "    \"doesn't\",\n",
    "    'don',\n",
    "    \"don't\",\n",
    "    'done',\n",
    "    'down',\n",
    "    'except',\n",
    "    'few',\n",
    "    'hadn',\n",
    "    \"hadn't\",\n",
    "    'hasn',\n",
    "    \"hasn't\",\n",
    "    'haven',\n",
    "    \"haven't\",\n",
    "    'however',\n",
    "    'isn',\n",
    "    \"isn't\",\n",
    "    'least',\n",
    "    'mightn',\n",
    "    \"mightn't\",\n",
    "    'move',\n",
    "    'much',\n",
    "    'must',\n",
    "    'mustn',\n",
    "    \"mustn't\",\n",
    "    'needn',\n",
    "    \"needn't\",\n",
    "    'neither',\n",
    "    'never',\n",
    "    'nevertheless',\n",
    "    'no',\n",
    "    'nobody',\n",
    "    'none',\n",
    "    'noone',\n",
    "    'nor',\n",
    "    'not',\n",
    "    'nothing',\n",
    "    'should',\n",
    "    \"should've\",\n",
    "    'shouldn',\n",
    "    \"shouldn't\",\n",
    "    'too',\n",
    "    'top',\n",
    "    'up',\n",
    "    'very'\n",
    "    'wasn',\n",
    "    \"wasn't\",\n",
    "    'well',\n",
    "    'weren',\n",
    "    \"weren't\",\n",
    "    'won',\n",
    "    \"won't\",\n",
    "    'wouldn',\n",
    "    \"wouldn't\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_words).union(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stop_words = stop_words-exceptionStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\",disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token(review):\n",
    "    return tokenizer.tokenize(str(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(review):\n",
    "    return [token for token in review if token not in final_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(review):\n",
    "    lemma_result = []\n",
    "    \n",
    "    for words in review:\n",
    "        doc = nlp(words)\n",
    "        for token in doc:\n",
    "            lemma_result.append(token.lemma_)\n",
    "    return lemma_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(review):\n",
    "    review = make_token(review)\n",
    "    review = remove_stopwords(review)\n",
    "    return lemmatization(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35 s, sys: 70.8 ms, total: 35.1 s\n",
      "Wall time: 35.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews = list(map(lambda review: pipeline(review),reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bromwell',\n",
       "  'high',\n",
       "  'cartoon',\n",
       "  'comedy',\n",
       "  'run',\n",
       "  'time',\n",
       "  'program',\n",
       "  'school',\n",
       "  'life',\n",
       "  'teacher',\n",
       "  'year',\n",
       "  'teach',\n",
       "  'profession',\n",
       "  'lead',\n",
       "  'believe',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'satire',\n",
       "  'much',\n",
       "  'close',\n",
       "  'reality',\n",
       "  'teacher',\n",
       "  'scramble',\n",
       "  'survive',\n",
       "  'financially',\n",
       "  'insightful',\n",
       "  'student',\n",
       "  'right',\n",
       "  'pathetic',\n",
       "  'teacher',\n",
       "  'pomp',\n",
       "  'pettiness',\n",
       "  'situation',\n",
       "  'remind',\n",
       "  'school',\n",
       "  'know',\n",
       "  'student',\n",
       "  'see',\n",
       "  'episode',\n",
       "  'student',\n",
       "  'repeatedly',\n",
       "  'try',\n",
       "  'burn',\n",
       "  'down',\n",
       "  'school',\n",
       "  'immediately',\n",
       "  'recall',\n",
       "  'high',\n",
       "  'classic',\n",
       "  'line',\n",
       "  'inspector',\n",
       "  'sack',\n",
       "  'teacher',\n",
       "  'student',\n",
       "  'welcome',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'expect',\n",
       "  'adult',\n",
       "  'age',\n",
       "  'think',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'far',\n",
       "  'fetch',\n",
       "  'pity',\n",
       "  'isn'],\n",
       " ['story',\n",
       "  'man',\n",
       "  'unnatural',\n",
       "  'feeling',\n",
       "  'pig',\n",
       "  'start',\n",
       "  'open',\n",
       "  'scene',\n",
       "  'terrific',\n",
       "  'example',\n",
       "  'absurd',\n",
       "  'comedy',\n",
       "  'formal',\n",
       "  'orchestra',\n",
       "  'audience',\n",
       "  'turn',\n",
       "  'insane',\n",
       "  'violent',\n",
       "  'mob',\n",
       "  'crazy',\n",
       "  'chantings',\n",
       "  'singer',\n",
       "  'unfortunately',\n",
       "  'stay',\n",
       "  'absurd',\n",
       "  'time',\n",
       "  'no',\n",
       "  'general',\n",
       "  'narrative',\n",
       "  'eventually',\n",
       "  'make',\n",
       "  'too',\n",
       "  'putt',\n",
       "  'era',\n",
       "  'should',\n",
       "  'turn',\n",
       "  'cryptic',\n",
       "  'dialogue',\n",
       "  'shakespeare',\n",
       "  'easy',\n",
       "  'grader',\n",
       "  'technical',\n",
       "  'level',\n",
       "  'well',\n",
       "  'think',\n",
       "  'good',\n",
       "  'cinematography',\n",
       "  'future',\n",
       "  'great',\n",
       "  'vilmos',\n",
       "  'zsigmond',\n",
       "  'future',\n",
       "  'star',\n",
       "  'sally',\n",
       "  'kirkland',\n",
       "  'frederic',\n",
       "  'forrest',\n",
       "  'see',\n",
       "  'briefly']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(reviews,size=embedding_dimension, window=3, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28165"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.7116297483444214),\n",
       " ('alright', 0.68076491355896),\n",
       " ('okay', 0.645799994468689),\n",
       " ('darn', 0.6437720060348511),\n",
       " ('excellent', 0.6200926303863525)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"good\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrible', 0.7325153946876526),\n",
       " ('awful', 0.7025212645530701),\n",
       " ('terrible', 0.6949663758277893),\n",
       " ('lousy', 0.6866083145141602),\n",
       " ('suck', 0.6829736828804016)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"bad\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrible', 0.7325153946876526),\n",
       " ('awful', 0.7025212645530701),\n",
       " ('terrible', 0.6949663758277893),\n",
       " ('lousy', 0.6866083145141602)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=\"bad\",topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57665604"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similarity(\"good\",\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33806083"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similarity(\"good\",\"be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class', 0.7562885284423828),\n",
       " ('college', 0.7530918121337891),\n",
       " ('schooler', 0.7420896291732788),\n",
       " ('schoolers', 0.7284963726997375),\n",
       " ('bidder', 0.7034502029418945)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"school\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('satire', 0.6727117300033569),\n",
       " ('farce', 0.6670421957969666),\n",
       " ('slapstick', 0.6608940958976746),\n",
       " ('parody', 0.6515933275222778),\n",
       " ('humor', 0.6184934377670288)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"comedy\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thrill', 0.640326738357544),\n",
       " ('suspense', 0.6267827749252319),\n",
       " ('gory', 0.5814146995544434),\n",
       " ('excitement', 0.5696775913238525),\n",
       " ('pace', 0.5687879920005798)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"action\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('depress', 0.7650548219680786),\n",
       " ('heartwarming', 0.713385820388794),\n",
       " ('cry', 0.7070283889770508),\n",
       " ('happy', 0.6953425407409668),\n",
       " ('honest', 0.6870818138122559)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"sad\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('solid', 0.4205891489982605),\n",
       " ('fine', 0.37321388721466064),\n",
       " ('splendid', 0.3685866892337799),\n",
       " ('headliner', 0.3574002981185913),\n",
       " ('gibney', 0.3493482172489166)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(negative=[\"bad\"],positive=[\"decent\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "SEED = 2222\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(embedding_model,review):\n",
    "    index_review = []\n",
    "    for word in review:\n",
    "        try:\n",
    "            index_review.append(embedding_model.vocab[word].index)\n",
    "        except: \n",
    "             pass\n",
    "    return torch.tensor(index_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_value = len(word_vectors.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28165"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_review = list(map(lambda review: word2idx(word_vectors,review),reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = torch.Tensor(word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim,embedding_weights):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_weights)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, text_lengths):\n",
    "        #x [sent length , batch size]\n",
    "        embedded = self.embedding(x) #[sentect len,batch size,embedding dim]\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
    "        packed_output, hidden = self.rnn(packed_embedded)#[sentence length,batch size, hidden dim],[1,batch size,hidden dim]\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = padding_value\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(28165, 100)\n",
       "  (rnn): RNN(100, 256)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
