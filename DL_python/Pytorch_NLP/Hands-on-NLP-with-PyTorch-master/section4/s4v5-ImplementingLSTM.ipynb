{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    reviewsFile = open('../data/reviews.txt','r')\n",
    "    reviews = list(map(lambda x:x[:-1],reviewsFile.readlines()))\n",
    "    reviewsFile.close()\n",
    "\n",
    "    labelsFile = open('../data/labels.txt','r')\n",
    "    labels = list(map(lambda x:x[:-1],labelsFile.readlines()))\n",
    "    labelsFile.close()\n",
    "    \n",
    "    return reviews,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews,labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(\"\\w+\\'?\\w+|\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptionStopWords = {\n",
    "    'again',\n",
    "    'against',\n",
    "    'ain',\n",
    "    'almost',\n",
    "    'among',\n",
    "    'amongst',\n",
    "    'amount',\n",
    "    'anyhow',\n",
    "    'anyway',\n",
    "    'aren',\n",
    "    \"aren't\",\n",
    "    'below',\n",
    "    'bottom',\n",
    "    'but',\n",
    "    'cannot',\n",
    "    'couldn',\n",
    "    \"couldn't\",\n",
    "    'didn',\n",
    "    \"didn't\",\n",
    "    'doesn',\n",
    "    \"doesn't\",\n",
    "    'don',\n",
    "    \"don't\",\n",
    "    'done',\n",
    "    'down',\n",
    "    'except',\n",
    "    'few',\n",
    "    'hadn',\n",
    "    \"hadn't\",\n",
    "    'hasn',\n",
    "    \"hasn't\",\n",
    "    'haven',\n",
    "    \"haven't\",\n",
    "    'however',\n",
    "    'isn',\n",
    "    \"isn't\",\n",
    "    'least',\n",
    "    'mightn',\n",
    "    \"mightn't\",\n",
    "    'move',\n",
    "    'much',\n",
    "    'must',\n",
    "    'mustn',\n",
    "    \"mustn't\",\n",
    "    'needn',\n",
    "    \"needn't\",\n",
    "    'neither',\n",
    "    'never',\n",
    "    'nevertheless',\n",
    "    'no',\n",
    "    'nobody',\n",
    "    'none',\n",
    "    'noone',\n",
    "    'nor',\n",
    "    'not',\n",
    "    'nothing',\n",
    "    'should',\n",
    "    \"should've\",\n",
    "    'shouldn',\n",
    "    \"shouldn't\",\n",
    "    'too',\n",
    "    'top',\n",
    "    'up',\n",
    "    'very'\n",
    "    'wasn',\n",
    "    \"wasn't\",\n",
    "    'well',\n",
    "    'weren',\n",
    "    \"weren't\",\n",
    "    'won',\n",
    "    \"won't\",\n",
    "    'wouldn',\n",
    "    \"wouldn't\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_words).union(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stop_words = stop_words-exceptionStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\",disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token(review):\n",
    "    return tokenizer.tokenize(str(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(review):\n",
    "    return [token for token in review if token not in final_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(review):\n",
    "    lemma_result = []\n",
    "    \n",
    "    for words in review:\n",
    "        doc = nlp(words)\n",
    "        for token in doc:\n",
    "            lemma_result.append(token.lemma_)\n",
    "    return lemma_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(review):\n",
    "    review = make_token(review)\n",
    "    review = remove_stopwords(review)\n",
    "    return lemmatization(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.4 s, sys: 103 ms, total: 38.5 s\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews = list(map(lambda review: pipeline(review),reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bromwell',\n",
       "  'high',\n",
       "  'cartoon',\n",
       "  'comedy',\n",
       "  'run',\n",
       "  'time',\n",
       "  'program',\n",
       "  'school',\n",
       "  'life',\n",
       "  'teacher',\n",
       "  'year',\n",
       "  'teach',\n",
       "  'profession',\n",
       "  'lead',\n",
       "  'believe',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'satire',\n",
       "  'much',\n",
       "  'close',\n",
       "  'reality',\n",
       "  'teacher',\n",
       "  'scramble',\n",
       "  'survive',\n",
       "  'financially',\n",
       "  'insightful',\n",
       "  'student',\n",
       "  'right',\n",
       "  'pathetic',\n",
       "  'teacher',\n",
       "  'pomp',\n",
       "  'pettiness',\n",
       "  'situation',\n",
       "  'remind',\n",
       "  'school',\n",
       "  'know',\n",
       "  'student',\n",
       "  'see',\n",
       "  'episode',\n",
       "  'student',\n",
       "  'repeatedly',\n",
       "  'try',\n",
       "  'burn',\n",
       "  'down',\n",
       "  'school',\n",
       "  'immediately',\n",
       "  'recall',\n",
       "  'high',\n",
       "  'classic',\n",
       "  'line',\n",
       "  'inspector',\n",
       "  'sack',\n",
       "  'teacher',\n",
       "  'student',\n",
       "  'welcome',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'expect',\n",
       "  'adult',\n",
       "  'age',\n",
       "  'think',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'far',\n",
       "  'fetch',\n",
       "  'pity',\n",
       "  'isn'],\n",
       " ['story',\n",
       "  'man',\n",
       "  'unnatural',\n",
       "  'feeling',\n",
       "  'pig',\n",
       "  'start',\n",
       "  'open',\n",
       "  'scene',\n",
       "  'terrific',\n",
       "  'example',\n",
       "  'absurd',\n",
       "  'comedy',\n",
       "  'formal',\n",
       "  'orchestra',\n",
       "  'audience',\n",
       "  'turn',\n",
       "  'insane',\n",
       "  'violent',\n",
       "  'mob',\n",
       "  'crazy',\n",
       "  'chantings',\n",
       "  'singer',\n",
       "  'unfortunately',\n",
       "  'stay',\n",
       "  'absurd',\n",
       "  'time',\n",
       "  'no',\n",
       "  'general',\n",
       "  'narrative',\n",
       "  'eventually',\n",
       "  'make',\n",
       "  'too',\n",
       "  'putt',\n",
       "  'era',\n",
       "  'should',\n",
       "  'turn',\n",
       "  'cryptic',\n",
       "  'dialogue',\n",
       "  'shakespeare',\n",
       "  'easy',\n",
       "  'grader',\n",
       "  'technical',\n",
       "  'level',\n",
       "  'well',\n",
       "  'think',\n",
       "  'good',\n",
       "  'cinematography',\n",
       "  'future',\n",
       "  'great',\n",
       "  'vilmos',\n",
       "  'zsigmond',\n",
       "  'future',\n",
       "  'star',\n",
       "  'sally',\n",
       "  'kirkland',\n",
       "  'frederic',\n",
       "  'forrest',\n",
       "  'see',\n",
       "  'briefly']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(reviews,size=embedding_dimension, window=3, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28165"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.7306010723114014),\n",
       " ('alright', 0.6821662187576294),\n",
       " ('darn', 0.658607542514801),\n",
       " ('okay', 0.6319257616996765),\n",
       " ('fair', 0.6208689212799072)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"good\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrible', 0.7087627053260803),\n",
       " ('terrible', 0.7078632116317749),\n",
       " ('lame', 0.6842957735061646),\n",
       " ('ritchie', 0.6836880445480347),\n",
       " ('awful', 0.6716997027397156)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"bad\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrible', 0.7087627053260803),\n",
       " ('terrible', 0.7078632116317749),\n",
       " ('lame', 0.6842957735061646),\n",
       " ('ritchie', 0.6836880445480347)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=\"bad\",topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57048476"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similarity(\"good\",\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27348474"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similarity(\"good\",\"be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('college', 0.782921552658081),\n",
       " ('class', 0.7638683319091797),\n",
       " ('schooler', 0.7603098750114441),\n",
       " ('schoolers', 0.7321504950523376),\n",
       " ('doddsville', 0.7250348329544067)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"school\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('humor', 0.6835606098175049),\n",
       " ('slapstick', 0.6748438477516174),\n",
       " ('satire', 0.6725203990936279),\n",
       " ('farce', 0.668818473815918),\n",
       " ('drama', 0.6469231843948364)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"comedy\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('suspense', 0.635033905506134),\n",
       " ('thrill', 0.5868341326713562),\n",
       " ('gory', 0.5625475645065308),\n",
       " ('courtroom', 0.5608855485916138),\n",
       " ('overlong', 0.5559324622154236)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"action\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('depress', 0.7547096014022827),\n",
       " ('heartwarming', 0.7460227012634277),\n",
       " ('cry', 0.7299706935882568),\n",
       " ('genuinely', 0.6788302659988403),\n",
       " ('honestly', 0.6724828481674194)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"sad\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fine', 0.4173683524131775),\n",
       " ('solid', 0.4102835953235626),\n",
       " ('support', 0.40012240409851074),\n",
       " ('ensemble', 0.39356565475463867),\n",
       " ('large', 0.386192262172699)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(negative=[\"bad\"],positive=[\"decent\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "SEED = 2222\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(embedding_model,review):\n",
    "    index_review = []\n",
    "    for word in review:\n",
    "        try:\n",
    "            index_review.append(embedding_model.vocab[word].index)\n",
    "        except: \n",
    "             pass\n",
    "    return torch.tensor(index_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_value = len(word_vectors.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28165"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_review = list(map(lambda review: word2idx(word_vectors,review),reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = torch.Tensor(word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout,embedding_weights):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_weights)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, text_lengths):\n",
    "        #x [sent length , batch size]\n",
    "        embedded = self.embedding(x) #[sentect len,batch size,embedding dim]\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)#output[sent length,batch size,hiddendin*num of directions],[numberlayers*num of dir,batch size,hid dim]\n",
    "        #[f0,b0,f1,b1,.......fn,bn]\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = padding_value\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(28165, 100)\n",
       "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'negative', 'positive', 'negative', 'positive']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0 if label == 'negative' else 1 for label in labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(index_review, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 5000 4000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),len(X_test),len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 5000 4000\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train),len(y_test),len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterator_func(X,y):\n",
    "    size = len(X)\n",
    "    permutation = np.random.permutation(size)\n",
    "    iterator = []\n",
    "    for i in range(0,size, batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch = {}\n",
    "        batch[\"text\"] = [X[i] for i in indices]\n",
    "        batch[\"label\"] = [y[i] for i in indices]\n",
    "        \n",
    "        batch[\"text\"],batch[\"label\"] = zip(*sorted(zip(batch[\"text\"],batch[\"label\"]),key=lambda x: len(x[0]),reverse=True))\n",
    "        batch[\"length\"] = [len(review) for review in batch[\"text\"]]\n",
    "        batch[\"length\"] = torch.IntTensor(batch[\"length\"])\n",
    "        batch[\"text\"] = torch.nn.utils.rnn.pad_sequence(batch[\"text\"],batch_first=True).t()\n",
    "        batch[\"label\"] = torch.Tensor(batch[\"label\"])\n",
    "        \n",
    "        batch[\"label\"]  = batch[\"label\"].to(device)\n",
    "        batch[\"length\"] = batch[\"length\"].to(device) \n",
    "        batch[\"text\"]   = batch[\"text\"].to(device) \n",
    "        \n",
    "        iterator.append(batch)\n",
    "        \n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iterator_func(X_train,y_train)\n",
    "valid_iterator = iterator_func(X_val,y_val)\n",
    "test_iterator = iterator_func(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 40 32\n"
     ]
    }
   ],
   "source": [
    "print(len(train_iterator),len(test_iterator),len(valid_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch[\"text\"],batch[\"length\"]).squeeze(1)\n",
    "        loss = criterion(predictions, batch[\"label\"])\n",
    "        acc = binary_accuracy(predictions, batch[\"label\"])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch[\"text\"],batch[\"length\"]).squeeze(1)\n",
    "            loss = criterion(predictions, batch[\"label\"])\n",
    "            acc = binary_accuracy(predictions, batch[\"label\"])\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.513 | Train Acc: 74.94% | Val. Loss: 0.423 | Val. Acc: 80.91% |\n",
      "| Epoch: 02 | Train Loss: 0.411 | Train Acc: 81.57% | Val. Loss: 0.381 | Val. Acc: 83.96% |\n",
      "| Epoch: 03 | Train Loss: 0.385 | Train Acc: 83.10% | Val. Loss: 0.350 | Val. Acc: 84.86% |\n",
      "| Epoch: 04 | Train Loss: 0.361 | Train Acc: 84.71% | Val. Loss: 0.355 | Val. Acc: 83.98% |\n",
      "| Epoch: 05 | Train Loss: 0.429 | Train Acc: 80.15% | Val. Loss: 0.384 | Val. Acc: 81.71% |\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.399 | Test Acc: 82.21% |\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    tokenized = pipeline(sentence)\n",
    "    indexed = word2idx(word_vectors,tokenized)\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.sigmoid(model(tensor,torch.LongTensor([len(indexed)]).to(device)))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8104231953620911"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"this is a awesome movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6436399221420288"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"this is not an action movie, is a  very good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6326010227203369"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"this is comedy movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04732838273048401"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"this is an awful movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11437103152275085"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"this is a bad movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
