{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    reviewsFile = open('../data/reviews.txt','r')\n",
    "    reviews = list(map(lambda x:x[:-1],reviewsFile.readlines()))\n",
    "    reviewsFile.close()\n",
    "\n",
    "    labelsFile = open('../data/labels.txt','r')\n",
    "    labels = list(map(lambda x:x[:-1],labelsFile.readlines()))\n",
    "    labelsFile.close()\n",
    "    \n",
    "    return reviews,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews,labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(\"\\w+\\'?\\w+|\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptionStopWords = {\n",
    "    'again',\n",
    "    'against',\n",
    "    'ain',\n",
    "    'almost',\n",
    "    'among',\n",
    "    'amongst',\n",
    "    'amount',\n",
    "    'anyhow',\n",
    "    'anyway',\n",
    "    'aren',\n",
    "    \"aren't\",\n",
    "    'below',\n",
    "    'bottom',\n",
    "    'but',\n",
    "    'cannot',\n",
    "    'couldn',\n",
    "    \"couldn't\",\n",
    "    'didn',\n",
    "    \"didn't\",\n",
    "    'doesn',\n",
    "    \"doesn't\",\n",
    "    'don',\n",
    "    \"don't\",\n",
    "    'done',\n",
    "    'down',\n",
    "    'except',\n",
    "    'few',\n",
    "    'hadn',\n",
    "    \"hadn't\",\n",
    "    'hasn',\n",
    "    \"hasn't\",\n",
    "    'haven',\n",
    "    \"haven't\",\n",
    "    'however',\n",
    "    'isn',\n",
    "    \"isn't\",\n",
    "    'least',\n",
    "    'mightn',\n",
    "    \"mightn't\",\n",
    "    'move',\n",
    "    'much',\n",
    "    'must',\n",
    "    'mustn',\n",
    "    \"mustn't\",\n",
    "    'needn',\n",
    "    \"needn't\",\n",
    "    'neither',\n",
    "    'never',\n",
    "    'nevertheless',\n",
    "    'no',\n",
    "    'nobody',\n",
    "    'none',\n",
    "    'noone',\n",
    "    'nor',\n",
    "    'not',\n",
    "    'nothing',\n",
    "    'should',\n",
    "    \"should've\",\n",
    "    'shouldn',\n",
    "    \"shouldn't\",\n",
    "    'too',\n",
    "    'top',\n",
    "    'up',\n",
    "    'very'\n",
    "    'wasn',\n",
    "    \"wasn't\",\n",
    "    'well',\n",
    "    'weren',\n",
    "    \"weren't\",\n",
    "    'won',\n",
    "    \"won't\",\n",
    "    'wouldn',\n",
    "    \"wouldn't\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_words).union(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stop_words = stop_words-exceptionStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\",disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token(review):\n",
    "    return tokenizer.tokenize(str(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(review):\n",
    "    return [token for token in review if token not in final_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(review):\n",
    "    lemma_result = []\n",
    "    \n",
    "    for words in review:\n",
    "        doc = nlp(words)\n",
    "        for token in doc:\n",
    "            lemma_result.append(token.lemma_)\n",
    "    return lemma_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(review):\n",
    "    review = make_token(review)\n",
    "    review = remove_stopwords(review)\n",
    "    return lemmatization(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.4 s, sys: 8.84 ms, total: 37.5 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews = list(map(lambda review: pipeline(review),reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bromwell',\n",
       "  'high',\n",
       "  'cartoon',\n",
       "  'comedy',\n",
       "  'run',\n",
       "  'time',\n",
       "  'program',\n",
       "  'school',\n",
       "  'life',\n",
       "  'teacher',\n",
       "  'year',\n",
       "  'teach',\n",
       "  'profession',\n",
       "  'lead',\n",
       "  'believe',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'satire',\n",
       "  'much',\n",
       "  'close',\n",
       "  'reality',\n",
       "  'teacher',\n",
       "  'scramble',\n",
       "  'survive',\n",
       "  'financially',\n",
       "  'insightful',\n",
       "  'student',\n",
       "  'right',\n",
       "  'pathetic',\n",
       "  'teacher',\n",
       "  'pomp',\n",
       "  'pettiness',\n",
       "  'situation',\n",
       "  'remind',\n",
       "  'school',\n",
       "  'know',\n",
       "  'student',\n",
       "  'see',\n",
       "  'episode',\n",
       "  'student',\n",
       "  'repeatedly',\n",
       "  'try',\n",
       "  'burn',\n",
       "  'down',\n",
       "  'school',\n",
       "  'immediately',\n",
       "  'recall',\n",
       "  'high',\n",
       "  'classic',\n",
       "  'line',\n",
       "  'inspector',\n",
       "  'sack',\n",
       "  'teacher',\n",
       "  'student',\n",
       "  'welcome',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'expect',\n",
       "  'adult',\n",
       "  'age',\n",
       "  'think',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'far',\n",
       "  'fetch',\n",
       "  'pity',\n",
       "  'isn'],\n",
       " ['story',\n",
       "  'man',\n",
       "  'unnatural',\n",
       "  'feeling',\n",
       "  'pig',\n",
       "  'start',\n",
       "  'open',\n",
       "  'scene',\n",
       "  'terrific',\n",
       "  'example',\n",
       "  'absurd',\n",
       "  'comedy',\n",
       "  'formal',\n",
       "  'orchestra',\n",
       "  'audience',\n",
       "  'turn',\n",
       "  'insane',\n",
       "  'violent',\n",
       "  'mob',\n",
       "  'crazy',\n",
       "  'chantings',\n",
       "  'singer',\n",
       "  'unfortunately',\n",
       "  'stay',\n",
       "  'absurd',\n",
       "  'time',\n",
       "  'no',\n",
       "  'general',\n",
       "  'narrative',\n",
       "  'eventually',\n",
       "  'make',\n",
       "  'too',\n",
       "  'putt',\n",
       "  'era',\n",
       "  'should',\n",
       "  'turn',\n",
       "  'cryptic',\n",
       "  'dialogue',\n",
       "  'shakespeare',\n",
       "  'easy',\n",
       "  'grader',\n",
       "  'technical',\n",
       "  'level',\n",
       "  'well',\n",
       "  'think',\n",
       "  'good',\n",
       "  'cinematography',\n",
       "  'future',\n",
       "  'great',\n",
       "  'vilmos',\n",
       "  'zsigmond',\n",
       "  'future',\n",
       "  'star',\n",
       "  'sally',\n",
       "  'kirkland',\n",
       "  'frederic',\n",
       "  'forrest',\n",
       "  'see',\n",
       "  'briefly']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(reviews,size=embedding_dimension, window=3, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28165"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.7149477005004883),\n",
       " ('alright', 0.6797058582305908),\n",
       " ('darn', 0.6612451672554016),\n",
       " ('nice', 0.635985255241394),\n",
       " ('okay', 0.6258107423782349)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"good\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.7072927355766296),\n",
       " ('horrible', 0.6914027333259583),\n",
       " ('suck', 0.6833032369613647),\n",
       " ('lousy', 0.6696577668190002),\n",
       " ('lame', 0.6681134700775146)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"bad\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.7072927355766296),\n",
       " ('horrible', 0.6914027333259583),\n",
       " ('suck', 0.6833032369613647),\n",
       " ('lousy', 0.6696577668190002)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=\"bad\",topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56167686"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similarity(\"good\",\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31550848"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similarity(\"good\",\"be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('schooler', 0.779565691947937),\n",
       " ('college', 0.7704999446868896),\n",
       " ('class', 0.7457226514816284),\n",
       " ('bromwell', 0.7275199890136719),\n",
       " ('student', 0.719336986541748)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"school\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slapstick', 0.701862633228302),\n",
       " ('satire', 0.6545994281768799),\n",
       " ('parody', 0.6525259017944336),\n",
       " ('drama', 0.6442978382110596),\n",
       " ('spoof', 0.6419641971588135)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"comedy\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('suspense', 0.6146787405014038),\n",
       " ('thrill', 0.5885767340660095),\n",
       " ('cliffhanging', 0.5708556771278381),\n",
       " ('gory', 0.5699746608734131),\n",
       " ('cq', 0.5642054677009583)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"action\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('depress', 0.7681834697723389),\n",
       " ('heartwarming', 0.7197287678718567),\n",
       " ('cry', 0.6938855051994324),\n",
       " ('happy', 0.6869232058525085),\n",
       " ('honest', 0.6752169132232666)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"sad\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('solid', 0.4306844472885132),\n",
       " ('fine', 0.3992552161216736),\n",
       " ('splendid', 0.3872664272785187),\n",
       " ('fantastic', 0.38341987133026123),\n",
       " ('support', 0.37757763266563416)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(negative=[\"bad\"],positive=[\"decent\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "SEED = 2222\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(embedding_model,review):\n",
    "    index_review = []\n",
    "    for word in review:\n",
    "        try:\n",
    "            index_review.append(embedding_model.vocab[word].index)\n",
    "        except: \n",
    "             pass\n",
    "    return torch.tensor(index_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_value = len(word_vectors.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28165"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_review = list(map(lambda review: word2idx(word_vectors,review),reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = torch.Tensor(word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim,embedding_weights):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_weights)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, text_lengths):\n",
    "        #x [sent length , batch size]\n",
    "        embedded = self.embedding(x) #[sentect len,batch size,embedding dim]\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
    "        packed_output, hidden = self.rnn(packed_embedded)#[sentence length,batch size, hidden dim],[1,batch size,hidden dim]\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = padding_value\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(28165, 100)\n",
       "  (rnn): RNN(100, 256)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'negative', 'positive', 'negative', 'positive']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0 if label == 'negative' else 1 for label in labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(index_review, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 5000 4000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),len(X_test),len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 5000 4000\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train),len(y_test),len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterator_func(X,y):\n",
    "    size = len(X)\n",
    "    permutation = np.random.permutation(size)\n",
    "    iterator = []\n",
    "    for i in range(0,size, batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch = {}\n",
    "        batch[\"text\"] = [X[i] for i in indices]\n",
    "        batch[\"label\"] = [y[i] for i in indices]\n",
    "        \n",
    "        batch[\"text\"],batch[\"label\"] = zip(*sorted(zip(batch[\"text\"],batch[\"label\"]),key=lambda x: len(x[0]),reverse=True))\n",
    "        batch[\"length\"] = [len(review) for review in batch[\"text\"]]\n",
    "        batch[\"length\"] = torch.IntTensor(batch[\"length\"])\n",
    "        batch[\"text\"] = torch.nn.utils.rnn.pad_sequence(batch[\"text\"],batch_first=True).t()\n",
    "        batch[\"label\"] = torch.Tensor(batch[\"label\"])\n",
    "        \n",
    "        batch[\"label\"]  = batch[\"label\"].to(device)\n",
    "        batch[\"length\"] = batch[\"length\"].to(device) \n",
    "        batch[\"text\"]   = batch[\"text\"].to(device) \n",
    "        \n",
    "        iterator.append(batch)\n",
    "        \n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iterator_func(X_train,y_train)\n",
    "valid_iterator = iterator_func(X_val,y_val)\n",
    "test_iterator = iterator_func(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 40 32\n"
     ]
    }
   ],
   "source": [
    "print(len(train_iterator),len(test_iterator),len(valid_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch[\"text\"],batch[\"length\"]).squeeze(1)\n",
    "        loss = criterion(predictions, batch[\"label\"])\n",
    "        acc = binary_accuracy(predictions, batch[\"label\"])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch[\"text\"],batch[\"length\"]).squeeze(1)\n",
    "            loss = criterion(predictions, batch[\"label\"])\n",
    "            acc = binary_accuracy(predictions, batch[\"label\"])\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.694 | Train Acc: 50.51% | Val. Loss: 0.696 | Val. Acc: 50.22% |\n",
      "| Epoch: 02 | Train Loss: 0.691 | Train Acc: 52.19% | Val. Loss: 0.693 | Val. Acc: 51.46% |\n",
      "| Epoch: 03 | Train Loss: 0.687 | Train Acc: 53.73% | Val. Loss: 0.690 | Val. Acc: 53.32% |\n",
      "| Epoch: 04 | Train Loss: 0.684 | Train Acc: 55.58% | Val. Loss: 0.687 | Val. Acc: 55.30% |\n",
      "| Epoch: 05 | Train Loss: 0.682 | Train Acc: 57.12% | Val. Loss: 0.685 | Val. Acc: 57.15% |\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.683 | Test Acc: 57.21% |\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
