{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    reviewsFile = open('../data/reviews.txt','r')\n",
    "    reviews = list(map(lambda x:x[:-1],reviewsFile.readlines()))\n",
    "    reviewsFile.close()\n",
    "\n",
    "    labelsFile = open('../data/labels.txt','r')\n",
    "    labels = list(map(lambda x:x[:-1],labelsFile.readlines()))\n",
    "    labelsFile.close()\n",
    "    \n",
    "    return reviews,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews,labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(\"\\w+\\'?\\w+|\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptionStopWords = {\n",
    "    'again',\n",
    "    'against',\n",
    "    'ain',\n",
    "    'almost',\n",
    "    'among',\n",
    "    'amongst',\n",
    "    'amount',\n",
    "    'anyhow',\n",
    "    'anyway',\n",
    "    'aren',\n",
    "    \"aren't\",\n",
    "    'below',\n",
    "    'bottom',\n",
    "    'but',\n",
    "    'cannot',\n",
    "    'couldn',\n",
    "    \"couldn't\",\n",
    "    'didn',\n",
    "    \"didn't\",\n",
    "    'doesn',\n",
    "    \"doesn't\",\n",
    "    'don',\n",
    "    \"don't\",\n",
    "    'done',\n",
    "    'down',\n",
    "    'except',\n",
    "    'few',\n",
    "    'hadn',\n",
    "    \"hadn't\",\n",
    "    'hasn',\n",
    "    \"hasn't\",\n",
    "    'haven',\n",
    "    \"haven't\",\n",
    "    'however',\n",
    "    'isn',\n",
    "    \"isn't\",\n",
    "    'least',\n",
    "    'mightn',\n",
    "    \"mightn't\",\n",
    "    'move',\n",
    "    'much',\n",
    "    'must',\n",
    "    'mustn',\n",
    "    \"mustn't\",\n",
    "    'needn',\n",
    "    \"needn't\",\n",
    "    'neither',\n",
    "    'never',\n",
    "    'nevertheless',\n",
    "    'no',\n",
    "    'nobody',\n",
    "    'none',\n",
    "    'noone',\n",
    "    'nor',\n",
    "    'not',\n",
    "    'nothing',\n",
    "    'should',\n",
    "    \"should've\",\n",
    "    'shouldn',\n",
    "    \"shouldn't\",\n",
    "    'too',\n",
    "    'top',\n",
    "    'up',\n",
    "    'very'\n",
    "    'wasn',\n",
    "    \"wasn't\",\n",
    "    'well',\n",
    "    'weren',\n",
    "    \"weren't\",\n",
    "    'won',\n",
    "    \"won't\",\n",
    "    'wouldn',\n",
    "    \"wouldn't\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_words).union(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stop_words = stop_words-exceptionStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\",disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token(review):\n",
    "    return tokenizer.tokenize(str(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(review):\n",
    "    return [token for token in review if token not in final_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(review):\n",
    "    lemma_result = []\n",
    "    \n",
    "    for words in review:\n",
    "        doc = nlp(words)\n",
    "        for token in doc:\n",
    "            lemma_result.append(token.lemma_)\n",
    "    return lemma_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(review):\n",
    "    review = make_token(review)\n",
    "    review = remove_stopwords(review)\n",
    "    return lemmatization(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 s, sys: 88.2 ms, total: 39.1 s\n",
      "Wall time: 39.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews = list(map(lambda review: pipeline(review),reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bromwell',\n",
       "  'high',\n",
       "  'cartoon',\n",
       "  'comedy',\n",
       "  'run',\n",
       "  'time',\n",
       "  'program',\n",
       "  'school',\n",
       "  'life',\n",
       "  'teacher',\n",
       "  'year',\n",
       "  'teach',\n",
       "  'profession',\n",
       "  'lead',\n",
       "  'believe',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'satire',\n",
       "  'much',\n",
       "  'close',\n",
       "  'reality',\n",
       "  'teacher',\n",
       "  'scramble',\n",
       "  'survive',\n",
       "  'financially',\n",
       "  'insightful',\n",
       "  'student',\n",
       "  'right',\n",
       "  'pathetic',\n",
       "  'teacher',\n",
       "  'pomp',\n",
       "  'pettiness',\n",
       "  'situation',\n",
       "  'remind',\n",
       "  'school',\n",
       "  'know',\n",
       "  'student',\n",
       "  'see',\n",
       "  'episode',\n",
       "  'student',\n",
       "  'repeatedly',\n",
       "  'try',\n",
       "  'burn',\n",
       "  'down',\n",
       "  'school',\n",
       "  'immediately',\n",
       "  'recall',\n",
       "  'high',\n",
       "  'classic',\n",
       "  'line',\n",
       "  'inspector',\n",
       "  'sack',\n",
       "  'teacher',\n",
       "  'student',\n",
       "  'welcome',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'expect',\n",
       "  'adult',\n",
       "  'age',\n",
       "  'think',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'far',\n",
       "  'fetch',\n",
       "  'pity',\n",
       "  'isn'],\n",
       " ['story',\n",
       "  'man',\n",
       "  'unnatural',\n",
       "  'feeling',\n",
       "  'pig',\n",
       "  'start',\n",
       "  'open',\n",
       "  'scene',\n",
       "  'terrific',\n",
       "  'example',\n",
       "  'absurd',\n",
       "  'comedy',\n",
       "  'formal',\n",
       "  'orchestra',\n",
       "  'audience',\n",
       "  'turn',\n",
       "  'insane',\n",
       "  'violent',\n",
       "  'mob',\n",
       "  'crazy',\n",
       "  'chantings',\n",
       "  'singer',\n",
       "  'unfortunately',\n",
       "  'stay',\n",
       "  'absurd',\n",
       "  'time',\n",
       "  'no',\n",
       "  'general',\n",
       "  'narrative',\n",
       "  'eventually',\n",
       "  'make',\n",
       "  'too',\n",
       "  'putt',\n",
       "  'era',\n",
       "  'should',\n",
       "  'turn',\n",
       "  'cryptic',\n",
       "  'dialogue',\n",
       "  'shakespeare',\n",
       "  'easy',\n",
       "  'grader',\n",
       "  'technical',\n",
       "  'level',\n",
       "  'well',\n",
       "  'think',\n",
       "  'good',\n",
       "  'cinematography',\n",
       "  'future',\n",
       "  'great',\n",
       "  'vilmos',\n",
       "  'zsigmond',\n",
       "  'future',\n",
       "  'star',\n",
       "  'sally',\n",
       "  'kirkland',\n",
       "  'frederic',\n",
       "  'forrest',\n",
       "  'see',\n",
       "  'briefly']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(reviews,size=embedding_dimension, window=3, min_count=3, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28165"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.7319575548171997),\n",
       " ('alright', 0.6960811018943787),\n",
       " ('okay', 0.6700797080993652),\n",
       " ('darn', 0.6603134870529175),\n",
       " ('great', 0.6344092488288879)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"good\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrible', 0.7185400724411011),\n",
       " ('lame', 0.6830708384513855),\n",
       " ('terrible', 0.6805494427680969),\n",
       " ('suck', 0.672660768032074),\n",
       " ('lousy', 0.6538549661636353)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"bad\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrible', 0.7185400724411011),\n",
       " ('lame', 0.6830708384513855),\n",
       " ('terrible', 0.6805494427680969),\n",
       " ('suck', 0.672660768032074)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=\"bad\",topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58493686"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similarity(\"good\",\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2628381"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similarity(\"good\",\"be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('college', 0.765923261642456),\n",
       " ('schooler', 0.7632982134819031),\n",
       " ('class', 0.7375858426094055),\n",
       " ('student', 0.7067117094993591),\n",
       " ('teacher', 0.6980537176132202)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"school\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('farce', 0.6577758193016052),\n",
       " ('satire', 0.6503036022186279),\n",
       " ('slapstick', 0.6476813554763794),\n",
       " ('humor', 0.6358456611633301),\n",
       " ('parody', 0.6339165568351746)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"comedy\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('suspense', 0.608113169670105),\n",
       " ('gory', 0.5757965445518494),\n",
       " ('thrill', 0.5684385299682617),\n",
       " ('fantasy', 0.5647292137145996),\n",
       " ('overlong', 0.5647001266479492)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"action\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('depress', 0.7832858562469482),\n",
       " ('cry', 0.7202650308609009),\n",
       " ('happy', 0.7075549960136414),\n",
       " ('heartwarming', 0.7021917700767517),\n",
       " ('anyways', 0.6821246147155762)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(word=\"sad\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fine', 0.41307878494262695),\n",
       " ('solid', 0.4069543182849884),\n",
       " ('splendid', 0.37130245566368103),\n",
       " ('tremendous', 0.36157888174057007),\n",
       " ('outstanding', 0.35796302556991577)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(negative=[\"bad\"],positive=[\"decent\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
