{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softmax\n",
    "\n",
    "classify multiclass datasets에서 출발. binary와 달리, 이 분류는 obstacle이 있다.\n",
    "\n",
    "* replacement of sigmoid activation function.\n",
    "    sigmoid는 binary classification에서 상당히 유용한 함수다. 0~1 사이값 반환 = '확률'로 인식할 수 있음.\n",
    "    단, multiclass의 경우는 이 함수를 사용할 수가 없다.\n",
    "그래서 등장한 게 softmax function.\n",
    "\n",
    "\n",
    "Neural network를 통과하면, weights와 bias의 연산 결과로 특정 score가 생길 거다. 예컨대 분류 대상이 3개라면 3개 항목에 대한 각각의 score.\n",
    "\n",
    "하지만 score 자체는 큰 의미가 없다. practical use를 위해서는 이걸 확률로 변환해야 함\n",
    "\n",
    "확률 변환을 위해 고려할 사항은\n",
    "1. relative magnitudes of scores must be maintained. 예컨대 공 3개 비교.. 축구공이 2, 농구공이 1, 배구공이 0이라면 score of 2는 1보다 축구공일 가능성이 높아야 하고, 1은 0보다 배구공일 가능성이 높아야 한다.\n",
    "\n",
    "2. all probability values must add up to 1\n",
    "\n",
    "이 두 가지를 가능하게 하는 게 softmax function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feedforward process to determine the probability of sth being what it is -> similiar to how we did for binary classification. 데이터 넣고 통과시킨 다음 마지막 score에 softmax 적용하면 된다.\n",
    "\n",
    "---\n",
    "\n",
    "지도학습이니까, training model을 위해서는 'labeled data' 학습이 필요함. 여기서도 문제가 하나 있다.\n",
    "\n",
    "binary의 경우 0과 1만 있으면 되고, 두 값에는 dependency가 전혀 없다. 하지만 multiclass의 경우 dependency를 상정할 수 있다.\n",
    "\n",
    "예컨대 축구공은 2, 농구공은 1, 배구공은 0이라고 하면 세 값 사이에는 dependency(relation)가 존재함. 'label encodings'\n",
    "\n",
    "알고리즘이 'kind of order'로 인식할 수 있다는 점. 하나의 종류가 다른 하나보다 highly ordered로 인식되면 분류에 오류가 발생할 수 있다. (상호 독립적인 게 기본 전제기 때문에)\n",
    "\n",
    "그래서 'one-hot encoding' 방식을 사용한다. one-hot encoding을 써서 independent하게 만들어주는 것.\n",
    "\n",
    "\n",
    "따라서\n",
    "\n",
    "1. multiclass label을 one-hot encoding으로 변경해 준다\n",
    "2. 변경한 데이터셋을 train.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy\n",
    "in binary system. / in multiclass\n",
    "\n",
    "model이 좋고 나쁨을 평가할 때, lower cross entropy는 좋고 higher는 나쁘다. (정확도가 높다 / 낮다)\n",
    "\n",
    "\n",
    "multiclass의 경우?\n",
    "\n",
    "ex) \n",
    "\n",
    "    축구공 통과 -> 축구공 예측 확률 .4, 농구공 .2, 배구공 .4\n",
    "    배구공 통과 -> 축구공 .5, 농구공 .3, 배구공 .2\n",
    "    농구공 통과 -> 축구공 .3, 농구공 .6, 배구공 .1\n",
    "\n",
    "이라고 할 때, cross entropy 계산법은\n",
    "\n",
    " -(ln(.4) + ln(.6) + ln(.2)) = 3.04 가 된다. (one hot encoding의 결과로, 연산이 상대적으로 쉽다)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
