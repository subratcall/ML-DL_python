{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch1_자연어처리_개요.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPI/sb2HTm97te4v9EBYBRN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy2K9EUxKoBL",
        "colab_type": "text"
      },
      "source": [
        "# 자연어처리\n",
        "\n",
        "1. 감성분석 (Sentiment Analysis) -> 대량의 텍스트를 이해하고 수치화하는 작업\n",
        "2. 애플 시리, 아마존 알렉사처럼 사용자 의도 파악 + 대화\n",
        "3. 요약, 기계번역\n",
        "4. 입력 -> 원하는 것을 검색 및 답변을 주는 작업\n",
        "\n",
        "### 음성인식 분야\n",
        "\n",
        "영상처리보다 딥러닝 기술이 성공적으로 적용된 사례. 상용화까지 성공함\n",
        "기존의 음소 인식 (GMM) 방법을 DNN으로 대체해서 기존 방식의 성능을 혁신적으로 개선시킴.\n",
        "점차 음향모델 전체를 LSTM으로 대체하고 end-to-end 방식으로 성과를 내며 자리잡고 있다.\n",
        "\n",
        "### 기계번역\n",
        "\n",
        "딥러닝 이전 = 통계 기반 기계번역 (SMT).\n",
        "딥러닝 seq2seq 모델 구조 적용 이후 NMT 번역. 현재는 신경망 기계번역으로 대통합\n",
        "\n",
        "### 생성 모델 학습\n",
        "\n",
        "이미지 분류 / 텍스트 분류 같은 단순 분류를 넘어, 생성 모델 (GAN) 적용\n",
        "before : 데이터 x가 주어지면 알맞은 레이블 y를 찾아내는 것\n",
        "after : 데이터 x 분포 자체를 학습함. ex) 사람의 얼굴이 남자인지 여자인지 / 누구인지 -> 사람의 얼굴 자체를 묘사할 수 있는 모델을 훈련하는 식\n",
        "\n",
        "-> 적대적 학습 (Adversarial Learning), 변분 오토인코더 (Variational AutoEncoder) 등이 주목받고 있음.\n",
        "\n",
        "### 자연어 처리\n",
        "\n",
        "사람의 언어는 불연속적인 이산 (discrete) 심벌로 이루어져 있다. 따라서 모든 단어는 기본적으로 서로 다른 symbol이었고, 전통적인 자연어처리는 불연속적인 symbol로 데이터 취급. 데이터 보고 해석하기는 쉽지만, 모호성이나 유의성을 다룰 경우 어려웠다.\n",
        "\n",
        "word2vec등의 단어 임베딩으로 단어(토큰)을 연속적인 벡터로 나타낼 수 있게 되고, 직접적인 해석은 어려워진 대신 유의성이나 모호성 문제를 쉽게 해결할 수 있게 됐다. 딥러닝의 장점을 살린 end-to-end 모델이 구현되고, RNN 단점을 보완한 LSTM, GRU 활용법이 고도화되기 시작함. Attention의 등장으로 Long Sequential 데이터도 학습이 가능해졌다.\n",
        "\n",
        "#### 자연어 처리가 어려웠던 이유\n",
        "\n",
        "1. 모호성\n",
        "\n",
        "    - 단어의 중의성. \"차를 마시러 공원에 가던 차 안에서 나는 그녀에게 차였다\" 라는 문장을 영문 번역시키면, 제대로 번역해내는 번역업체는 별로 없다.\n",
        "    - 문장 내 정보 부족에 따른 구조해석. '나는 철수를 안 때렸다' -> 해석 여지가 많음.\n",
        "\n",
        "언어는 최소한의 표현으로 최대한의 정보를 표현하려는 효율성 측면에서 발전. 효율성 관점에서 쉽고 뻔한 정보는 생략됨. 사람은 이 생략된 구멍을 쉽게 해석 가능하지만, 컴퓨터는 그렇지 않음. ex) 단어 중의성 사례의 '차' : 맥락으로 이해해야 함\n",
        "\n",
        "2. 다양한 표현\n",
        "\n",
        "같은 사진을 묘사할 때도 여러 방법이 있다. 표현 형식 자체는 무한한 수준으로 만들어낼 수 있기 때문. \n",
        "\n",
        "3. 불연속적 데이터\n",
        "\n",
        "과거에는 데이터를 불연속적으로 취급했으므로 처리가 어렵지 않았다. but 딥러닝에 적용하려면 연속된 값으로 바꿔줘야 함. Embedding이 이 역할을 수행하고 있지만, 애초에 불연속적인 데이터를 바꾸는 작업이라서 완벽하진 않음.\n",
        "    - 차원의 저주: 불연속 데이터라서 생기는 문제. 데이터 종류만큼의 차원이 필요했었다. 현재는 segmentation + Embedding으로 dimension reduction으로 거의 해결한 상태\n",
        "    - 노이즈 / 정규화. 데이터에서 신호와 노이즈 구분은 중요하지만, 자연어는 이게 쉽지 않다. 노이즈를 제거하겠다고 뭐 하다가 단어가 조금이라도 바뀌면 의미변화가 크기 때문. 띄어쓰기나 어순 차이로 인한 normalization 이슈도 어려운 편.\n",
        "\n",
        "* 한국어가 특히 어려운 이유\n",
        "    - 교착어. 어순이 중요한 영어나 중국어와 달리, 어순은 덜 중요하고 어근에 접사가 붙어 단어를 이루고 의미 + 문법적 기능이 정해진다. 다시말해 어근에 어떤 접사가 붙느냐에 따라 수없이 다양한 의미가 만들어지고, 조합도 매우 많다. 이 특징이 parsing, 형태소 분석부터 언어 모델에 이르기까지 한국어가 매우 어려운 이유 중 하나.\n",
        "    - 띄어쓰기. 동양권은 근대에 들어 띄어쓰기가 도입됨. 애초에 띄어쓰기 고려해 발전한 언어가 아님. (없어도 의미 이해 지장이 덜한 편) 즉, 추가적인 분절로 띄어쓰기 정제하는 과정도 필요\n",
        "    - 평서문 / 의문문. 한국어는 평서문과 의문문이 같은 형태의 문장구조다. 마침표나 물음표 없으면 파악이 어려움. 특히 음성인식 결과로 나오는 텍스트는 더 어려움\n",
        "    - 주어 생략. 영어는 주어를 잘 생략하지 않지만, 한국어는 주어 생략하고 동사를 중시한다. 생략된 주어를 파악하는 게 인간은 쉽지만 컴퓨터는 어려움\n",
        "    - 한자 기반의 언어. 한자 자체는 각 글자의 의미가 합쳐져 하나의 단어 뜻을 만드는 형태. 하지만 한글이 한자를 대체하면서 '표어문자 -> 표음문자' 변환 중에 정보 손실이 생겼다. 인간은 이 손실을 문맥으로 해결하지만 컴퓨터는 어려움\n",
        "        - 이 문제는 특히 Subword 단위로 분절할 때 심해진다. ex) 문제점 = 문 제 점 으로 분절된다. 그런데 '제'만 해도, 결제 / 제공 등에서도 동일하게 사용됨. 임베딩 벡터는 결제, 제공, 문제점 세 개의 단어에서 나타나는 '제'를 동일한 단어로 임베딩하려 함. 결국 각각의 의미를 나타내는 평균 어딘가로 애매하게 임베딩되는 문제. (비단 딥러닝에서의 문제는 아님. 전통적 방식도 문제는 비슷)\n",
        "\n",
        " - 자연어처리 딥러닝 적용과정\n",
        "    1. word2vec : 고차원 공간에 단어가 어떻게 배치되는지 확인할 수 있게 됨. 비슷한 의미의 단어일수록 저차원의 공간에 가깝게 위치함. = 딥러닝 활용 자연어 처리 과정에서 네트워크 내부가 어떻게 작동하는지 실마리 확보.\n",
        "    2. RNN 대신 CNN을 적용할 경우 텍스트 분류보다 성능이 올라간다는 사실 확보. 단어 임베딩과 결합해 성능 극대화 가능. 그 외에도 형태소분석, 문장 파싱, 개체명 인식 (Named Entity Recognition), 의미역 결정 (Sementic Role labeling) 등에서 성과.\n",
        "    3. seq2seq 모델 등장, Attention 기법 등장 -> 기계번역에 적용되어 성과. 주어진 정보에 기반해 자유롭게 문장 생성하는 '자연어 생성'이 가능해짐.\n",
        "    4. 연속적인 방식으로 정보 읽고 쓰는 기법 & 신경망을 통해 메모리를 활용하는 기법들의 등장. 뉴럴 튜링 머신 (NTM), 디퍼런셜 뉴럴 컴퓨터 (DNC).\n",
        "\n",
        "자연어처리는 언어모델 자체가 문장에 대한 생성모델 학습이므로, VAE나 GAN같은 영상처리분야의 생성모델과는 궤가 약간 달랐다. 단, 기계번역의 성공으로 학계가 마주한 문제점은 딥러닝의 'Loss Function'과 기계번역을 위한 목적함수 'Object Function) 간 괴리 문제였다.\n",
        "\n",
        "영상처리 분야에서 MSE 손실함수 한계 극복을 위해 GAN을 도입했듯, 여기도 다른 유형의 손실함수가 필요했음.\n",
        "\n",
        "\n",
        "강화학습 분야의 policy gradient 방식을 자연어 생성에 적용하면서 '적대적 학습' 방식을 차용할 수 있게 됨. \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiwoYx50KeAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}