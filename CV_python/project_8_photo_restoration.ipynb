{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photo Restoration\n",
    "\n",
    "Damaged Photo를 받아서 clean up image로 변환하기.\n",
    "\n",
    "### Computational Photography\n",
    "\n",
    "photo restoration도 computational photography의 알고리즘을 사용한 방법.\n",
    "\n",
    "* digital image processing techniques used on images produced by cameras.\n",
    "* seek to enhance images via computational processing rather than use expensive optical processes. (비싼 카메라 장비가 제공하는 편의 대신, computational process로 고퀄 이미지를 뽑아내려는 시도) \n",
    "\n",
    "스마트폰에서 특히 많이 쓰이는 기술이라고 함.\n",
    "- Noise reduction\n",
    "- High dynamic range\n",
    "- image stabilization\n",
    "- panoramas\n",
    "- inpainting (removal of small noise, strokes, etc)\n",
    "\n",
    "\n",
    "\n",
    "**Inpainting** is the process of reconstructing lost or deteriorated parts of images and videos. It is an advanced form of interpolation that can be used to replace lost or corrupted parts of the image data.\n",
    "\n",
    "**cv2.inpaint**(input image, mask, inpaintRadius, Inpaint Method)\n",
    "\n",
    "**inpaintRadius** – Radius of a circular neighborhood of each point inpainted that is considered by the algorithm. Smaller values look less blurred, while larger values look more pixelated or blurred. \n",
    "\n",
    "작은 값을 쓰면 image tend to look less blurred points where the mask is. = noisy detail이 남아 있을 수 있다.\n",
    "<br>\n",
    "이미지 안에 있는 noise를 빡세게 줄이고 싶으면 이 값이 좀 더 커야 함.\n",
    "\n",
    "\n",
    "**Inpaint Methods**\n",
    "- INPAINT_NS - Navier-Stokes based method [Navier01] : 2001년에 고안됐고 지금도 쓰이고는 있으나, Tella가 intergrated more seamlessly, superior한 편이라고.\n",
    "\n",
    "- INPAINT_TELEA - Method by Alexandru Telea [Telea04] - Better as it integrates more seamlessley into the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load our damaged photo\n",
    "image = cv2.imread('./MasteringComputerVision-V1.03/Master OpenCV/images/abraham.jpg')\n",
    "cv2.imshow('Original Damaged Photo', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Load the photo where we've marked the damaged areas\n",
    "# damaged 부분을 강조한 mask파일. 이건 수작업으로 만들었다고 함. 없애고 싶은 부분을 그림판 같은 걸로, 흰색으로 draw line했다고.\n",
    "marked_damages = cv2.imread('./MasteringComputerVision-V1.03/Master OpenCV/images/mask.jpg', 0)\n",
    "cv2.imshow('Marked Damages', marked_damages)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Let's make a mask out of our marked image be changing all colors \n",
    "# that are not white, to black\n",
    "# mask 이미지 파일을 Threshold로 변환. damaged line만 잡아낸다. (흰색만 잡아내도록.)\n",
    "ret, thresh1 = cv2.threshold(marked_damages, 254, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold Binary', thresh1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Let's dilate (make thicker) our the marks w made\n",
    "# since thresholding has narrowed it slightly\n",
    "kernel = np.ones((7,7), np.uint8)\n",
    "mask = cv2.dilate(thresh1, kernel, iterations = 1) # boundary에 add pixel value였음. 그러니 이 사진에서 흰 줄이 더 thicker\n",
    "cv2.imshow('Dilated Mask', mask)\n",
    "cv2.imwrite(\"./MasteringComputerVision-V1.03/Master OpenCV/images/abraham_mask.png\", mask)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "restored = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "cv2.imshow('Restored', restored)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
