{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection.\n",
    "\n",
    "CV에서 가장 유용한 경우. Labeling Scenes에서부터 다방면에 걸쳐 쓰인다.\n",
    "\n",
    "recognition은 second level of Object detection. multiple object within img 확인. \n",
    "\n",
    "Template Matching: object detection의 기본. 비유하자면 사막에서 바늘 찾기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Waldo (Quickly find a specific pattern within image)\n",
    "\n",
    "input image를 받은 다음 grayscale로 변환. template에 해당하는 작은 이미지도 받은 다음 gray 변환.\n",
    "\n",
    "matchtemplate 함수를 이용함. 아래 예시의 경우 match method는 cv2.TM_CCOEFF를 사용. correlation coefficient를 말함\n",
    "\n",
    "* 링크에 올라간 함수들을 보면, 물론 특정 함수가 다른 함수보다 잘 match하는 경우는 있어도 전체적으로는 유사한 결과를 내는 편\n",
    "\n",
    "return값은 array이고, 이 값의 bounding box를 반환하는 함수가 cv2.minMaxLoc 함수.\n",
    "\n",
    "bounding box를 찾은 뒤, 원본그림에 box를 실제로 그린 것.\n",
    "\n",
    "### Notes on Template Matching\n",
    "\n",
    "There are a variety of methods to perform template matching, but in this case we are using the correlation coefficient which is specified by the flag **cv2.TM_CCOEFF.**\n",
    "\n",
    "So what exactly is the cv2.matchTemplate function doing?\n",
    "Essentially, this function takes a “sliding window” of our waldo query image and slides it across our puzzle image from left to right and top to bottom, one pixel at a time. Then, for each of these locations, we compute the correlation coefficient to determine how “good” or “bad” the match is. \n",
    "\n",
    "Regions with sufficiently high correlation can be considered “matches” for our waldo template.\n",
    "From there, all we need is a call to cv2.minMaxLoc on Line 22 to find where our “good” matches are.\n",
    "That’s really all there is to template matching!\n",
    "\n",
    "http://docs.opencv.org/2.4/modules/imgproc/doc/object_detection.html      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load input image and convert to grayscale\n",
    "image = cv2.imread('./MasteringComputerVision-V1.03/Master OpenCV/images/WaldoBeach.jpg')\n",
    "cv2.imshow('Where is Waldo?', image)\n",
    "cv2.waitKey(0)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Load Template image\n",
    "template = cv2.imread('./MasteringComputerVision-V1.03/Master OpenCV/images/waldo.jpg',0)\n",
    "\n",
    "result = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "#Create Bounding Box\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + 50, top_left[1] + 50)\n",
    "cv2.rectangle(image, top_left, bottom_right, (0,0,255), 5)\n",
    "\n",
    "cv2.imshow('Where is Waldo?', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데, 원본 이미지를 잘라낸 특정 이미지를 사용하는 경우 몇 가지 limitation이 있다.\n",
    "\n",
    "* scale, rotation, another angle(perspective), brightness / contrast / hue 등에 전부 무력함. distortion에도 취약\n",
    "\n",
    "이런 문제를 해결하려는 노력으로 \"image Features\"가 있다.\n",
    "\n",
    "image features = 'summaries of pictures'. \n",
    "\n",
    "\"interesting areas that are somewhat unique to the specific image.\" \n",
    "\n",
    "보통 key point features / interest points라고도 불린다.\n",
    "\n",
    "#### 중요한 이유??\n",
    "\n",
    "analyse, describe, match image에서 상당히 중요한 기능을 하기 때문. \n",
    "\n",
    "image alignment (파노라마 switching = 이미지 매칭하기 등) / 3D reconstruction, robot navigation, object recognition, motion tracking 등등 다양한 분야에 응용된다.\n",
    "\n",
    "**\"interesting\"의 정의??**\n",
    "\n",
    "= distinct, unique한 정보를 담고 있는 부분이라고 이해하면 쉽다. High change of intensities, Corners of edges 등등.\n",
    "\n",
    "주의할 점: 노이즈도 appear 'informative' when it's not. 그래서 cleaning 작업이 필요.\n",
    "\n",
    "\n",
    "#### interesting features의 특징\n",
    "\n",
    "* repeatable : 사진 내 여러 곳에서 비슷하게 발견됨\n",
    "* distinctive : 각각의 feature는 unique, different to other features of same scene\n",
    "* compactness / efficiency : 해당 이미지의 특징을 잡아낼 수 있는 최소한의 feature를 말함. \n",
    "* locality : features occupies a small area of image, and is robust to clutter & occlusion.\n",
    "\n",
    "1. Corners as Features.\n",
    "\n",
    "window shift시 intensity 차이가 크다. \n",
    " - edge : change in one direction (상하 / 좌우)\n",
    " - corner : change in all direction (상하좌우 전부 다)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
