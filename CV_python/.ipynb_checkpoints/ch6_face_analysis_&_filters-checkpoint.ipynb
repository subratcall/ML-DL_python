{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting facial landmarks\n",
    "\n",
    "Use some libraries to do some complex visual analysis & filters.\n",
    "\n",
    "Dlib, Merge face / Live Face swap과 face reader (detect and count yawn)\n",
    "<hr>\n",
    "\n",
    "이전 프로젝트에 사용한 HAAR classifier로 Face Detection이 가능했다. \n",
    "\n",
    "하지만 face swap과 같은 기술들은 단순히 Face의 bounding box만 확인하는 형태로는 불가능. 이전에 배운 bounding Box로 얼굴 떼내는 것만으로는 Swap은 불가능하다.\n",
    "\n",
    "**\"얼굴 형태를 좀 더 제대로 표현하는 것. detecting facial landmarks.\"**\n",
    "\n",
    " = 눈코입과 같은 key facial landmark를 빠르게 찾아내는 것이 중요하다.\n",
    " \n",
    "동작 과정에서 어려운 것들\n",
    "\n",
    "1. identifying Facial features(key facial landmarks)\n",
    "2. Warp the image to fit the new & different facial expression.\n",
    "3. color matching\n",
    "4. Seamless boarders on the edges of the new swapped image.\n",
    "\n",
    "python에서는 dlib이라는 라이브러리 활용.\n",
    "\n",
    "pretrained model을 python.exe가 있는 dir에 두라고 한다.\n",
    "```py\n",
    "import sys\n",
    "print(sys.executable) ## 여기 dir.\n",
    "```\n",
    "\n",
    "사용할 pretrained model은 총 68개의 key points of facial landmarks를 제공한다.\n",
    "\n",
    "* mouth points: 48 ~ 61\n",
    "* right brow points: 17 ~ 21\n",
    "* left brow points: 22 to 27\n",
    "* right eye point: 36 to 42\n",
    "* left eye point: 42 to 48\n",
    "* nose point: 27 to 35\n",
    "* jaw point: 0 to 17\n",
    "\n",
    "See blog post here - https://matthewearl.github.io/2015/07/28/switching-eds-with-python/\n",
    "\n",
    "\n",
    "#### Install Instructions for dlib\n",
    "\n",
    "- Download and Install Dlib\n",
    "\n",
    "https://sourceforge.net/projects/dclib/\n",
    "\n",
    "- Extract files in C:/dlib \n",
    "- Use command prompt to Cd to folder and run “python setup.py install”\n",
    "- 난 anaconda로 처리.\n",
    "\n",
    "#### Download the pre-trained model here \n",
    "\n",
    "http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
    "\n",
    "- Place this file in your default ipython notebook folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# 모델 파일\n",
    "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "# 모델 predictor 불러오기\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "# facial detector 불러오기\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Exception handle.\n",
    "class TooManyFaces(Exception):\n",
    "    pass\n",
    "\n",
    "class NoFaces(Exception):\n",
    "    pass\n",
    "\n",
    "def get_landmarks(im):\n",
    "    rects = detector(im, 1)\n",
    "    # 얼굴이 있는 부분을 감지해서 array를 반환한다.\n",
    "\n",
    "    if len(rects) > 1:\n",
    "        raise TooManyFaces\n",
    "    if len(rects) == 0:\n",
    "        raise NoFaces\n",
    "    # Face detect되면, 그 face의 rectangle bounding box를 제공한다.\n",
    "    return np.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "def annotate_landmarks(im, landmarks):\n",
    "    # how to plot numbers onto the face.\n",
    "    \n",
    "    im = im.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(im, str(idx), pos,\n",
    "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale=0.4,\n",
    "                    \n",
    "                    color=(0, 0, 255))\n",
    "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
    "    return im\n",
    "\n",
    "image = cv2.imread('./MasteringComputerVision-V1.03/Master OpenCV/images/Obama.jpg')\n",
    "landmarks = get_landmarks(image)\n",
    "image_with_landmarks = annotate_landmarks(image, landmarks)\n",
    "\n",
    "cv2.imshow('Result', image_with_landmarks)\n",
    "cv2.imwrite('image_with_landmarks.jpg',image_with_landmarks)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Swap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# Copyright (c) 2015 Matthew Earl\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "# \n",
    "#     The above copyright notice and this permission notice shall be included\n",
    "#     in all copies or substantial portions of the Software.\n",
    "# \n",
    "#     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n",
    "#     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "#     MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n",
    "#     NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n",
    "#     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n",
    "#     OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n",
    "#     USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "\"\"\"\n",
    "This is the code behind the Switching Eds blog post:\n",
    "    http://matthewearl.github.io/2015/07/28/switching-eds-with-python/\n",
    "See the above for an explanation of the code below.\n",
    "To run the script you'll need to install dlib (http://dlib.net) including its\n",
    "Python bindings, and OpenCV. You'll also need to obtain the trained model from\n",
    "sourceforge:\n",
    "    http://sourceforge.net/projects/dclib/files/dlib/v18.10/shape_predictor_68_face_landmarks.dat.bz2\n",
    "Unzip with `bunzip2` and change `PREDICTOR_PATH` to refer to this file. The\n",
    "script is run like so:\n",
    "    ./faceswap.py <head image> <face image>\n",
    "If successful, a file `output.jpg` will be produced with the facial features\n",
    "from `<head image>` replaced with the facial features from `<face image>`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**작동 원리.**\n",
    "\n",
    "Face image 2개를 input으로 넣는다. face 2의 이미지를 face 1에 넣는다고 가정하자. 즉 face 1 얼굴에 face 2 마스크를 씌우려는 것.\n",
    "\n",
    "두 개 이미지를 각각 Dlib의 Face detector 함수에 넣는다. 리턴값으로 rectangle이 나올 것 (얼굴 부분)\n",
    "\n",
    "이 output을 predictor함수에 넣는다. facial feature extracting 기능을 수행하는 함수임. 리턴값으로는 facial landmarks가 array of x, y coordinates를 얻을 수 있음.\n",
    "\n",
    "각각의 얼굴 이미지의 Facial landmarks를 얻은 뒤, have to produce mapping btwn them.ㅡtransformation from points 함수가 그 역할을 한다. mathmatical sth.. 이며, input으로 facial landmark of Face 1, 2가 주어지면 리턴값으로 transformation matrix (M) that maps points from on face to the next (3*3). 이 matrix를 얻기 위해 minimize a loss function... -> Procrustes Analysis 라고 함.\n",
    "\n",
    "이렇게 얻은 landmark position을 갖고 face mask를 만든다 (get_face_mask). 얼굴에서 원하는 부분만 swap하기 위해 필요한 함수. input으로 face 2와 face 2의 facial landmark이며, 리턴값은 image mask다. face 2의 image part 중 face 1에 overlaid 될 부분이라고 보면 됨. 그리고 smooth transition을 위해서는 mask의 edge를 블러 처리하는 작업이 필요하다.\n",
    "\n",
    "이제, 아까 만든 transformation matrix (M)을 사용해서 이미지를 mapping한다. input으로는 face 1, transformation Matrix M, image 2의 shape / matrix dimension 이며, 리턴값으론 face 1 with face 2 overlaid on it.\n",
    "\n",
    "이제, combined할 준비가 됐다. Combined Mask 함수를 실행하면 됨. 인풋으로는 face 1, facial landmark of face 1, 직전함수에서 만든 warped mask이며, 실행 결과는 combined mask. face 1 베이스에 face 2 이미지가 visible한 상황.\n",
    "\n",
    "마지막으로, 주변 color 맞추는 작업인 correct_colours 함수를 실행해 준다. 인풋은 face 1, warped_mask2(reverse of warped_mask), facial landmark of image 1이며, 리턴은 색깔 보정된 이미지."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy\n",
    "from time import sleep\n",
    "import sys\n",
    "\n",
    "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "SCALE_FACTOR = 1 \n",
    "FEATHER_AMOUNT = 11\n",
    "\n",
    "# defining facial keys.\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "JAW_POINTS = list(range(0, 17))\n",
    "\n",
    "# Points used to line up the images.\n",
    "ALIGN_POINTS = (LEFT_BROW_POINTS + RIGHT_EYE_POINTS + LEFT_EYE_POINTS +\n",
    "                               RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS)\n",
    "\n",
    "# Points from the second image to overlay on the first. The convex hull of each\n",
    "# element will be overlaid.\n",
    "OVERLAY_POINTS = [\n",
    "    LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS,\n",
    "    NOSE_POINTS + MOUTH_POINTS,\n",
    "]\n",
    "\n",
    "# Amount of blur to use during colour correction, as a fraction of the\n",
    "# pupillary distance.\n",
    "COLOUR_CORRECT_BLUR_FRAC = 0.6\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n",
    "class TooManyFaces(Exception):\n",
    "    pass\n",
    "\n",
    "class NoFaces(Exception):\n",
    "    pass\n",
    "\n",
    "def get_landmarks(im):\n",
    "    # Returns facial landmarks as (x,y) coordinates\n",
    "    rects = detector(im, 1)\n",
    "    \n",
    "    if len(rects) > 1:\n",
    "        raise TooManyFaces\n",
    "    if len(rects) == 0:\n",
    "        raise NoFaces\n",
    "\n",
    "    return numpy.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "\n",
    "def annotate_landmarks(im, landmarks):\n",
    "    #Overlays the landmark points on the image itself\n",
    "    \n",
    "    im = im.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(im, str(idx), pos,\n",
    "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale=0.4,\n",
    "                    color=(0, 0, 255))\n",
    "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
    "    return im\n",
    "\n",
    "def draw_convex_hull(im, points, color):\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(im, points, color=color)\n",
    "    # convex hull = object를 감쌀 수 있는 가장 작은 Object. 외곽선이라고 생각하면 된다.\n",
    "\n",
    "def get_face_mask(im, landmarks):\n",
    "    # generate mask of image.\n",
    "    im = numpy.zeros(im.shape[:2], dtype=numpy.float64)\n",
    "\n",
    "    for group in OVERLAY_POINTS:\n",
    "        draw_convex_hull(im,\n",
    "                         landmarks[group],\n",
    "                         color=1)\n",
    "\n",
    "    im = numpy.array([im, im, im]).transpose((1, 2, 0))\n",
    "\n",
    "    im = (cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0) > 0) * 1.0\n",
    "    im = cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0)\n",
    "\n",
    "    return im\n",
    "    \n",
    "def transformation_from_points(points1, points2):\n",
    "    \"\"\"\n",
    "    Return an affine transformation [s * R | T] such that:\n",
    "        sum ||s*R*p1,i + T - p2,i||^2\n",
    "    is minimized.\n",
    "    \"\"\"\n",
    "    # Solve the procrustes problem by subtracting centroids, scaling by the\n",
    "    # standard deviation, and then using the SVD to calculate the rotation. See\n",
    "    # the following for more details:\n",
    "    #   https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem\n",
    "\n",
    "    # procrustes analysis 방법이라고 함.\n",
    "    \n",
    "    points1 = points1.astype(numpy.float64)\n",
    "    points2 = points2.astype(numpy.float64)\n",
    "\n",
    "    c1 = numpy.mean(points1, axis=0)\n",
    "    c2 = numpy.mean(points2, axis=0)\n",
    "    points1 -= c1\n",
    "    points2 -= c2\n",
    "\n",
    "    s1 = numpy.std(points1)\n",
    "    s2 = numpy.std(points2)\n",
    "    points1 /= s1\n",
    "    points2 /= s2\n",
    "\n",
    "    U, S, Vt = numpy.linalg.svd(points1.T * points2)\n",
    "\n",
    "    # The R we seek is in fact the transpose of the one given by U * Vt. This\n",
    "    # is because the above formulation assumes the matrix goes on the right\n",
    "    # (with row vectors) where as our solution requires the matrix to be on the\n",
    "    # left (with column vectors).\n",
    "    R = (U * Vt).T\n",
    "\n",
    "    return numpy.vstack([numpy.hstack(((s2 / s1) * R,\n",
    "                                       c2.T - (s2 / s1) * R * c1.T)),\n",
    "                         numpy.matrix([0., 0., 1.])])\n",
    "\n",
    "def read_im_and_landmarks(image):\n",
    "    im = image\n",
    "    # 연산속도를 늘리기 위해 resize 후 진행.\n",
    "    im = cv2.resize(im,None,fx=1, fy=1, interpolation = cv2.INTER_LINEAR)\n",
    "    im = cv2.resize(im, (im.shape[1] * SCALE_FACTOR,\n",
    "                         im.shape[0] * SCALE_FACTOR))\n",
    "    s = get_landmarks(im)\n",
    "\n",
    "    return im, s\n",
    "\n",
    "def warp_im(im, M, dshape):\n",
    "    output_im = numpy.zeros(dshape, dtype=im.dtype)\n",
    "    cv2.warpAffine(im,\n",
    "                   M[:2],\n",
    "                   (dshape[1], dshape[0]),\n",
    "                   dst=output_im,\n",
    "                   borderMode=cv2.BORDER_TRANSPARENT,\n",
    "                   flags=cv2.WARP_INVERSE_MAP)\n",
    "    return output_im\n",
    "\n",
    "def correct_colours(im1, im2, landmarks1):\n",
    "    blur_amount = COLOUR_CORRECT_BLUR_FRAC * numpy.linalg.norm(\n",
    "                              numpy.mean(landmarks1[LEFT_EYE_POINTS], axis=0) -\n",
    "                              numpy.mean(landmarks1[RIGHT_EYE_POINTS], axis=0))\n",
    "    blur_amount = int(blur_amount)\n",
    "    if blur_amount % 2 == 0:\n",
    "        blur_amount += 1\n",
    "    im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0)\n",
    "    im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0)\n",
    "\n",
    "    # Avoid divide-by-zero errors.\n",
    "    im2_blur += (128 * (im2_blur <= 1.0)).astype(im2_blur.dtype)\n",
    "\n",
    "    return (im2.astype(numpy.float64) * im1_blur.astype(numpy.float64) /\n",
    "                                                im2_blur.astype(numpy.float64))\n",
    "\n",
    "\n",
    "def swappy(image1, image2):\n",
    "       \n",
    "    # 이미지 두 개 받아서 landmark 가져온다.\n",
    "    im1, landmarks1 = read_im_and_landmarks(image1)\n",
    "    im2, landmarks2 = read_im_and_landmarks(image2)\n",
    "    \n",
    "    # transmission Matrix를 만들어낸다.\n",
    "    M = transformation_from_points(landmarks1[ALIGN_POINTS],\n",
    "                                   landmarks2[ALIGN_POINTS])\n",
    "    \n",
    "    mask = get_face_mask(im2, landmarks2)\n",
    "    warped_mask = warp_im(mask, M, im1.shape)\n",
    "    combined_mask = numpy.max([get_face_mask(im1, landmarks1), warped_mask],\n",
    "                              axis=0)\n",
    "\n",
    "    warped_im2 = warp_im(im2, M, im1.shape)\n",
    "    warped_corrected_im2 = correct_colours(im1, warped_im2, landmarks1)\n",
    "\n",
    "    output_im = im1 * (1.0 - combined_mask) + warped_corrected_im2 * combined_mask\n",
    "    cv2.imwrite('output.jpg', output_im)\n",
    "    image = cv2.imread('output.jpg')\n",
    "    return image\n",
    "   \n",
    "\n",
    "## Enter the paths to your input images here    \n",
    "image1 = cv2.imread('./MasteringComputerVision-V1.03/Master OpenCV/images/Hillary.jpg')\n",
    "image2 = cv2.imread('./MasteringComputerVision-V1.03/Master OpenCV/images/Trump.jpg')\n",
    "\n",
    "swapped = swappy(image1, image2)\n",
    "cv2.imshow('Face Swap 1', swapped)\n",
    "\n",
    "swapped = swappy(image2, image1)\n",
    "cv2.imshow('Face Swap 2', swapped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
