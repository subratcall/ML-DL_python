{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kaggle 접근 순서\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "1. EDA. 눈으로 훓어보고, 기초 통계 뽑아보고, 막대그래프 같은 걸로 단일 변수 시각화도 해보고,\n",
    "    산점도와 같은 변수 간 관계를 시각화\n",
    "    \n",
    "    \n",
    "2. 평가 척도 이해. kaggle의 문제의도 이해하는 것과 같으며, 어떤 예측값이 페널티를 크게 받고 어떤 값이 페널티를 덜 받는지 이해하기\n",
    "\n",
    "\n",
    "3. cross validation 기법 선정. 케글에서 안정적인 성적을 거두려면 신뢰할 수 있는 교차검증기법을 구축하는 게 중요하다.\n",
    "\n",
    "일반적인 교차검증 방법\n",
    "- 제공된 데이터를 5:5 ~ 9:1 비율로 train/validation으로 분류.\n",
    "- 훈련 데이터에는 학습을, validation에서 평가 척도 점수를 구한다\n",
    "- 1,2번을 10번 반복하여, 검증 데이터의 평균점수를 구한다\n",
    "\n",
    "알아두면 좋은 내용\n",
    "- 데이터 크기에 따라 train/validation 분리 비율이 다르다. 데이터가 크면 5:5도 괜찮고, 적을 경우 9:1. 재현성을 위해 random_seed 설정\n",
    "- 분리 방법으로는 random split 또는 정답 레이블의 비율을 유지하며 임의로 분리하는 stratified split을 수행한다.\n",
    "- 시계열 데이터라면 항상 train 데이터는 validation 데이터보다 과거로.\n",
    "- 1~2번을 반복하는 횟수 또한 데이터 크기와 한 번의 모델학습에 소요되는 시간을 고려한다. 데이터 크고 시간 많이 걸리면 1번만 수행해도 된다\n",
    "\n",
    "피처 엔지니어링\n",
    "- 변수값 스케일링, 이상값 제거, 결측치 대체, 범주형 데이터 변환, 변수 선정, 파생변수 생성 등 주어진 데이터를 학습에 쉽게 변형해 주는 것\n",
    "- 랭킹을 가르는 가장 중요한 요인. 딥러닝 경진대회는 모델 엔지니어링이 핵심이다\n",
    "\n",
    "모델 튜닝\n",
    "- 최적 파라미터를 찾는다. 신뢰할 수 있는 교차검증 기법이 구축됐으면 교차검증 점수가 가장 좋은 파라미터를 사용.\n",
    "- 중간 결과는 항상 저장한다\n",
    "\n",
    "앙상블\n",
    "- 다수의 모델을 앙상블한 게 좋은 성능을 보인다. 서로 다른 유형의 모델을 앙상블 하는 게 가장 효과가 좋다\n",
    "- 다수 계층의 모델을 학습하는 stacking 기법도 케글에서 자주 사용된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SW library\n",
    "\n",
    "트리 기반 모델이 많이 쓰이며, 상위 입상자들은 대부분 gradient boosting decision tree 라이브러리인 xgboost, lightgbm, catboost를 쓴다. \n",
    "\n",
    "모델의 다양성을 추가한다면 randomforest, extratree 모델을 제공하는 사이킷런도 씀\n",
    "\n",
    "neural net에서는 pytorch나 keras가 쓰임\n",
    "\n",
    "경진대회 변수 특징에 따라 선형 모델이 트리와 유사한 수준의 성능을 보이기도 한다. svm, logistic regression.\n",
    "\n",
    "램에 담을 수 없는 대규모 데이터 처리에는 Vowpal Wabbit. 하이퍼 파라미터 최적화에는 hyperopt, scikit-optimize, spearmint 등 AutoML 라이브러리를 사용한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "최소한의 성능을 보이는 기본 머신러닝 파이프라인을 말한다. 이걸 구축하는 이유는 두 가지.\n",
    "\n",
    "1. 머신러닝 파이프라인이 올바르게 동작하는지 확인할 수 있다. \n",
    "2. 새로운 아이디어를 구현한 모델의 성능을 비교할 수 있는 기준이다.\n",
    "\n",
    "\n",
    "## 도전할 만한 케글과제 선정하기\n",
    "\n",
    "1. 1000명 이상이 참여한 경진대회는 하드웨어 사양이 낮아도 학습 가능함. 입문자들이 참가하여 얻어가는 경진대회\n",
    "2. private leaderboard 상위 10등에 입상한 케글러의 코드가 공개된 것.\n",
    "\n",
    "이 책에서는 '제품 추천', '음성인식', '안전 운전자 예측', '산만한 운전자 감지' 4개를 선정.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
